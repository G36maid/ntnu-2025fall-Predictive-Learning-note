# Inductive Learning, Basic Learning Problems and Inductive Principles

## OUTLINE

2.0 Objectives + Background

- formalization of inductive learning
- classical statistics vs predictive approach

2.1 Terminology and Learning Problems
2.2 Basic Learning Methods and Complexity

Control

2.3 Inductive Principles
2.4 Alternative Learning Formulations
2.5 Summary

## 2.0 Objectives

- To quantify the notions of explanation,

prediction and model

- Introduce terminology
- Describe common learning problems

## Example: classification problem

training samples, model
Goal 1: explanation of training data
Goal 2: generalization (for future data)

• 

Learning (model estimation) is ill-posed

## Well posed

Three fundamental conditions:

– The problem must have a unique solution.
– The solution must depend continuously on the

data or the parameters.

– The solution must be stable against small
changes in the data or the parameters.
Ill posed: violate one or more of these
conditions, therefore, difficult to solve.

[What is an ill-posed problem](https://www.collimator.ai/reference-guides/what-is-an-ill-posed-problem)

## Example: imitation of system’s output
(regression problem)
• Common setting ~ function estimation

## Some terminologies

Learning is the process of estimating an unknown
(input, output) dependency or structure of a
System using a limited number of observations.

• Past observations ~ data points
• Explanation (model) ~ function
• 

Learning ~ function estimation (from

data)

• 

Prediction ~using the model to predict

new inputs

## General learning scenario

• Three components

• Unknown joint distribution P(x,y)
•
• 

Set of functions (possible models)
Pre-specified Loss function

(by convention, non-negative L )

Generator of samplesLearning MachineSystemxy$yˆ = f(x, \omega)$($L(y, f(x, \omega))$)

## Set of functions (possible models)

• Parametric regression (fixed-degree

polynomial)

EX: the set of functions is specified as a
polynomial of fixed degree and the training
data have a single predictor variable.

• Different w vectors result in different

functions.

## Inductive Learning Setting

• The learning machine observes samples (x ,y), and

returns an estimated response

• Recall ‘first-principle’ vs ‘empirical’ knowledge

→Two modes of inference: identification vs imitation

• Risk

$$min \int L(y, f(x, \omega)) dP(x, y)$$

Generatorof samplesLearningMachineSystemxf(x.w)LossL(f(x.w),y)y

## How should a Learning Machine
use training data?
• Inductive principle: a general prescription for
obtaining an estimate the‘‘true dependency’’ in
the class of approximating functions from the
available (finite) training data.

• A learning method is a constructive

implementation of an inductive principle for
selecting an estimate from a particular
.
set of functions

## Two Views of Empirical Inference

• 

Two approaches to empirical or statistical inference

EMPIRICAL DATA

KNOWLEDGE,
ASSUMPTIONS

STATISTICAL INFERENCE

PROBABILISTIC
MODELING

RISK-MINIMIZATION
APPROACH

• 

These two approaches are different both

technically/mathematically and philosophically

## Statistical Dependency vs Causality

• Statistical dependency does not imply

causality (~understanding)
Examples: male violence

married people live longer

• Causality is not necessary for prediction
• Dangerous to infer causality from data alone
(as common in social studies, politics etc.)
• Causality can be demonstrated by arguments
outside the data, or by carefully designed
experimental setting

## Classical Approaches to Inductive Inference

Generic problem: finite data →Model
Classical Statistics M1 ~ hypothesis testing
experimental data is generated by a given model
(single function ~ scientific theory)
Classical Statistics M2 ~ max likelihood
~ data generated by a parametric model for density.
Note: loss fct ~ likelihood (not application-specific)
→ The same methodology for all learning problems

R. Fisher: “uncertain inferences” from finite data
see: [The Logic of Inductive Inference](http://www.dcscience.net/fisher-1935.pdf)

## Summary and Discussion

• Math formulation useful for quantifying

- explanation ~ fitting error (training data)
- generalization ~ prediction error

• Natural assumptions

- future similar to past: stationary P(x,y),
i.i.d.data
- discrepancy measure or loss function,
i.e. MSE

## OUTLINE

2.0 Objectives
2.1 Terminology and Learning Problems

- supervised/ unsupervised
- classification
- regression etc.

2.2 Basic Learning Methods and Complexity

Control

2.3 Inductive Principles
2.4 Alternative Learning Formulations
2.5 Summary

## Supervised Learning: Regression
• Data in the form (x,y), where

- x is multivariate input (i.e. vector)
- y is univariate output (‘response’)

• Regression: y is real-valued

→ Estimation of real-valued function

$L(y, f(x)) = (y - f(x))^2$

## Regression Estimation Problem

Given: training data
Find a function that minimizes squared
error for a large number (N) of future samples:

BUT future data is unknown ~ P(x,y) unknown
→ All estimation problems are ill-posed

$$\min_{w} \frac{1}{n} \sum_{i=1}^{n} (y_i - f(x_i, w))^2$$

niyii,...2,1),,(=x
wfx

## Supervised Learning: Classification

• Data in the form (x,y), where

- x is multivariate input (i.e. vector)
- y is univariate output (‘response’)

• Classification: y is categorical (class label)

→ Estimation of indicator function

$$L(y, f(x)) = \begin{cases} 1 & \text{if } y \neq f(x) \\ 0 & \text{if } y = f(x) \end{cases}$$

## Density Estimation

• Data in the form (x), where

•
•

- x is multivariate input (feature vector)
Parametric form of density is given:
The loss function is likelihood or, more
common, the negative log-likelihood

•

The goal of learning is minimization of

from finite training data, yielding

$f(x,\omega)$
$L(f(x,\omega)) = -\ln(f(x,\omega))$
$$R(\omega) = - \int \ln(f(x,\omega))p(x)dx$$

## Unsupervised Learning 1

• Data in the form (x), where

- x is multivariate input (i.e. feature vector)

• Goal: data reduction or clustering

→ Clustering = estimation of mapping X→ C,

where $C = \{c_1, c_2, ..., c_m\}$ and

$L(x, f(x)) = (x - f(x))^2$

## Unsupervised Learning 2

• Data in the form (x), where

- x is multivariate input (i.e. vector)

• Goal: dimensionality reduction

→ Mapping is projection of the data onto
low-dimensional subspace, maximizing the
variance (e.g., PCA).

)(xf

## OUTLINE

2.0 Objectives
2.1 Terminology and Learning Problems
2.2 Basic Learning Methods and

Complexity Control
- Parametric modeling
- Non-parametric modeling
- Data reduction
- Complexity control
2.3 Inductive Principles
2.4 Alternative Learning Formulations
2.5 Summary

## Basic learning methods

General idea
•

Specify a wide set of possible models
where is an abstract set of ‘parameters’
Estimate model parameters by minimizing
some loss function for training data

• 

Learning methods differ in
• Chosen parameterization
Loss function used
•
• Optimization method used for parameter

estimation

$f(x, \omega)$
$\\omega^*\\omega$

## Parametric Modeling (~ERM)

Given training data
(1) Specify parametric model
(2) Estimate its parameters (via fitting to data)
Example: Linear regression F(x)= (w x) + b
•

niyii,...2,1),,(=x
$$\min_{b,w} \frac{1}{n} \sum_{i=1}^{n} (y_i - (w \cdot x_i + b))^2$$

## Parametric Modeling: classification

Given training data
(1) Specify parametric model
(2) Estimate its parameters (via fitting to data)
Example: univariate classification data set
(a) Linear decision boundary

(b) third-order polynomial

niyii,...2,1),,(=x
$f(x) = sign(x-b)$
$f(x) = sign(wx^2 + x + b)$

## Method of Maximum Likelihood

• The idea behind the method of maximum

likelihood is to estimate a parameter with the
value that makes the observed data most likely.

• When a probability mass function or

probability density function is considered to
be a function of the parameters, it is called a
likelihood function.

• The maximum likelihood estimate is the value of
the estimators that when substituted in for the
parameters maximizes the likelihood
function.

Navidi, William Cyrus. Statistics for engineers and scientists. Vol. 2. New York: McGraw-Hill, 2006.

## Parametric modeling in Statistics

• Goal of learning : density estimation
• Maximum Likelihood principle:

choose w* maximizing

equivalently, minimize negative log-
likelihood

$$P(\text{data}|\text{model}) = \prod_{i=1}^{n} P(x_i|w)$$

## Maximum Likelihood illustration

## Maximum Likelihood illustration (conti.)

## Non-Parametric Modeling

Given training data
Estimate the model (for given ) as
‘local average’ of the data.
Note: need to define ‘local’, ‘average’
•

Example: k-nearest neighbors regression

$y_0 = \frac{1}{k} \sum_{j=1}^{k} y_j$
niyii,...2,1),,(=x
0x

## Data Reduction Approach

Given training data, estimate the model as ‘compact

encoding’ of the data.

Note: ‘compact’ ~ # of bits to encode the model

or

# of bits to encode the data (MDL)

•

Example: piece-wise linear regression

How many parameters needed
for two-linear-component model?

## Data Reduction Approach (cont’d)

Data Reduction approaches are commonly used

•

for unsupervised learning tasks.
Example: clustering.
Training data encoded by 3 points (cluster centers)

Issues:
- How to find centers?
- How to select the

number of clusters?

H

## Diverse terminology (of learning methods)

• Many methods differ in parameterization
of admissible models or approximating
functions
- neural networks
- decision trees
- signal processing (~ wavelets)

• How training samples are used:

Batch methods
On-line or flow-through methods

),(ˆwfyx=

## Explanation vs Prediction

→ Importance of complexity control

(a) Classification

(b) Regression

## Complexity Control: parametric modeling

Consider regression estimation
Ten training samples
•

• 

Fitting linear and 2-nd order polynomial:

25.0),,0(222=+=whereNxy

## Complexity Control: local estimation

Consider regression estimation
Ten training samples from
•

• Using k-nn regression with k=1 and k=4:

25.0),,0(222=+=whereNxy

## Complexity Control (summary)
• Complexity (of admissible models) affects

generalization (for future data)
• Specific complexity indices for

– Parametric models: ~ # of parameters
– Local modeling: size of local region
– Data reduction: # of clusters

• Complexity control = choosing optimal
complexity (~ good generalization) for
given (training) data set

• not well-understood in classical statistics

## OUTLINE

2.0 Objectives
2.1 Terminology and Learning Problems
2.2 Basic Learning Methods and

Complexity Control
2.3 Inductive Principles

- Motivation
- Inductive Principles: Penalization,
SRM, Bayesian Inference

2.4 Alternative Learning Formulations
2.5 Summary

## Motivation (cont’d)

• Generalization from finite data requires:

a priori knowledge = any info outside the
data, e.g. ???
inductive principle = how to combine a
priori knowledge with training data
learning method = constructive
implementation of inductive principle

• Example: Empirical Risk Minimization ~

parametric modeling approach

## Motivation (cont’d)

• Example: Empirical Risk Minimization ~

parametric modeling approach

• Prior knowledge:

• Inductive principle:

e.g., the order of poly.

• Given the prior, we

might not choose high
order poly. functions.

25.0),,0(222=+=whereNxy

## Motivation (cont’d)

• Need for flexible (adaptive) methods

•

- wide (~ flexible) parameterization
→ ill-posed estimation problems
- need provisions for complexity control
Inductive Principles originate from
statistics, applied math, info theory,
learning theory – and they adopt distinctly
different terminology & concepts

$f(x,w)$

## Empirical Inference
Two approaches to empirical or statistical inference

•

EMPIRICAL DATA

KNOWLEDGE,
ASSUMPTIONS

STATISTICAL INFERENCE

PROBABILISTIC
MODELING

RISK-MINIMIZATION
APPROACH

• 

General strategies for obtaining good models from data
~ known as inductive principles in learning theory

## •

Inductive Principles

The main issue here is choosing the candidate
model of the right complexity to describe the
training data.
Inductive Principles differ in terms of
- representation (encoding) of a priori
knowledge
- mechanism for combining a priori knowledge
with data
- applicability when the true model does not
belong to admissible models
- availability of constructive procedures
(learning methods/ algorithms)

## Model Selection Procedures

• Cross-validation (CV)
• Regularization or Penalization
• Structural Risk Minimization
• Bayesian model selection

## Cross-validation

• Given a dataset, we divide it into two parts as training

and validation sets.

• Train candidate models of different complexities, and
test their error on the validation set left out during
training.

Alpaydin, Ethem. Introduction to machine learning. MIT press, 2020.

## Penalization

• Overcomes the limitations of ERM
• Penalized empirical risk functional

is non-negative penalty functional
specified a priori (independent of the data); its
larger values penalize complex functions.
is regularization parameter (non-negative
number) tuned to training data

Example: LASSO

$$R_{pen}(\omega) = R_{emp}(\omega) + \lambda \Phi(\omega)$$
(),fx

## Least absolute shrinkage and
selection operator (LASSO)
• A type of linear regression with penalization.
• The lasso procedure encourages simple, sparse

models (i.e. models with fewer parameters).

• Lower model complexity results in better

generalization.

• The goal of the algorithm is to minimize:

[LASSO Regression](https://www.statisticshowto.com/lasso-regression/)

## Structural Risk Minimization
• Complexity ordering on a set of admissible

models, as a nested structure

Examples: a set of polynomial models, polynomials
of degree m are a subset of polynomials of
degree (m+1).

The complexity is given by the number of free

parameters.

$S_0 \subset S_1 \subset S_2 \subset \dots$

## Structural Risk Minimization (conti.)

• The optimal choice of model complexity
provides the minimum of the expected
risk.

• Statistical learning theory (Vapnik 1995)
provides analytic upper-bound estimates
for expected risk.

## Bayesian Inference

• Probabilistic approach to inference
•

Explicitly defines a priori knowledge as prior
probability (distribution) on a set of model
parameters
Bayes formula for updating prior probability
using the evidence given by the data:

•

~ posterior probability

~ likelihood (probability that the data are

generated by a model)

$$P(\text{model}|\text{data}) = \frac{P(\text{data}|\text{model}) P(\text{model})}{P(\text{data})}$$
$P(\text{model}|\text{data})$
$P(\text{data}|\text{model})$

## Bayesian Density Estimation
• Consider parametric density estimation where

prior probability distribution
Then posterior probability distribution is updated

Narrow posterior
distribution using
Bayes rule

$$p(w|X) = \frac{p(X|w) p(w)}{p(X)}$$
$P(\text{model}) = p(w)$
$P(\text{model})$
$P(\text{model}|\text{data})$

## Implementation of Bayesian
Inference
EX: Classification problem
• The posterior probability of class Ci can be

calculated as

• For minimum error, chooses the class with
the highest posterior probability; that is, we

Alpaydin, Ethem. Introduction to machine learning. MIT press, 2020.

## MAP (Maximum A Posteriori)

[Difference Between Maximum Likelihood Estimation (MLE) and Maximum a Posteriori (MAP)](http://www.sefidian.com/2022/06/21/difference-between-maximum-likelihood-estimation-mle-and-maximum-a-posteriori-map/)

## MLE (Maximum Likelihood
Estimation)

[Difference Between Maximum Likelihood Estimation (MLE) and Maximum a Posteriori (MAP)](http://www.sefidian.com/2022/06/21/difference-between-maximum-likelihood-estimation-mle-and-maximum-a-posteriori-map/)

## MLE vs MAP

MLE is a special case of MAP when the prior is uniform!

[Difference Between Maximum Likelihood Estimation (MLE) and Maximum a Posteriori (MAP)](http://www.sefidian.com/2022/06/21/difference-between-maximum-likelihood-estimation-mle-and-maximum-a-posteriori-map/)

## Comparison of Inductive Principles

• Representation of a priori knowledge/ complexity:

•

penalty term, structure, prior distribution
Formal procedure for complexity control:
penalized risk, optimal element of a structure,
posterior distribution

• Constructive implementation of complexity control:
resampling, analytic bounds, marginalization
***See Table 2.1 in [Cherkassky & Mulier, 2007]***

## Comparison of Inductive
Principles

For MDL, ***See pages 51-55 in [Cherkassky & Mulier, 2007]***

## OUTLINE

2.0 Objectives
2.1 Terminology and Learning Problems
2.2 Basic Learning Methods and Complexity

Control

2.3 Inductive Principles
2.4 Alternative Learning Formulations

- Vapnik’s principle
- Examples of non-standard formulations
- Formalization of application domain

2.5 Summary

## Keep It Direct Principle

• Vapnik’s principle

For estimation with finite data, do not solve a
given problem by indirectly solving a more
general/harder problem as an intermediate step

Note 1: this is contrary to classical science
Note 2: contradicts classical statistical approach

• Examples

- Classification via density estimation etc.
- Non-standard inductive learning settings

## Assumptions for Inductive Learning

• Available (training) data format (x,y)
• Test samples (x-values) are unknown
• Stationary distribution, i.i.d samples
• Single model needs to be estimated
• Specific loss functions adopted for common tasks

(classification, regression etc.)

Generatorof samplesLearningMachineSystemxf(x.w)LossL(f(x.w),y)y

## Non-standard Learning Settings

• Available Data Format

- x-values of test samples are known
→ Transduction, semi-supervised learning
• Different (non-standard) Loss Function
- see example ‘learning the sign of a

function’

• Univariate Output (~ a single model)

- multiple models may be estimated from
available/training data

## Transduction

~ predicting function values at given points:
• Given labeled training set + x-values of test data
Estimate (predict) y-values for given test inputs
•

a priori knowledge assumptionsestimated modeltraining datapredicted outputinductiondeductiontransduction

## Transduction

• The supervised learning

algorithm will only have five
labeled points for modeling.

• Transduction has the

advantage of being able to
consider all of the points.
• EX: Label the unlabeled

points according to the local
estimation.

[Transduction (machine learning)](https://en.wikipedia.org/wiki/Transduction_(machine_learning))

## •

•

Multiple Model Estimation
Training data in the form (x,y), where
- x is multivariate input
- y is univariate real-valued output (‘response’)
Similar to standard regression, but subsets of
data may be described by different models

## Formalization of Application Problems
Problem Specification Step (in the general
experimental procedure) cannot be formalized

•

But
•

Several guidelines can be helpful during
formalization process

• Mapping process:

Application requirements → Learning formulation

•

Specific components of this mapping process
are shown next

## 

APPLICATION    NEEDSLossFunctionInput, output,other variablesTraining/test dataAdmissibleModelsFORMAL PROBLEM STATEMENTLEARNING THEORY

## Summary
• Standard Inductive Learning ~ function estimation

• Goal of learning (empirical inference):

to act/perform well, not system identification

• Important concepts:

- training data, test data
- loss function, prediction error (~ prediction risk)
- basic learning problems

• Complexity control

• Inductive principles – which is the ‘best’ ?

## Summary (cont’d)

• Assumptions for inductive learning
• Non-standard learning formulations
Aside: predictive modeling of

physical systems vs social systems

• For discussion think of example application that

requires non-standard learning formulation
Note: (a) do not use examples similar to ones

presented in my lectures and/or text book
(b) you can email your example(s) to
instructor (maximum half-a-page)